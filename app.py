import streamlit as stimport hmacimport pandas as pdimport sysimport gcfrom datetime import datetime, timedeltaimport timeimport osfrom streamlit_server_state import server_state, server_state_lockfrom helper.modelling import initialize# session initialization# last used timeif os.path.exists("metadata/last_used.txt") and "last_used" not in st.session_state:    file = open("metadata/last_used.txt", "r")    st.session_state["last_used"] = datetime.strptime(file.read(), '%Y-%m-%d %H:%M:%S.%f')    file.close()else:    st.session_state["last_used"] = datetime.now() - timedelta(hours=0, minutes=10)# last userif os.path.exists("metadata/user.txt"):    file = open("metadata/user.txt", "r")    st.session_state["last_user"] = file.read()    file.close()else:    st.session_state["last_user"] = "none"# passworddef check_password():    """Returns `True` if the user had the correct password."""    st.session_state["available"] = (datetime.now() - st.session_state["last_used"]).total_seconds() > 1 # available if last use more than 3 minutes ago            if not(st.session_state["available"]):        st.error(f"Application in use by {st.session_state['last_user']}. Refresh in 3 minutes, if they have stopped using it you will be able to log in.")    def password_entered():        """Checks whether a password entered by the user is correct."""        if hmac.compare_digest(st.session_state["password"], st.secrets["password"]):            st.session_state["password_correct"] = True            del st.session_state["password"]  # Don't store the password.        else:            st.session_state["password_correct"] = False    # Return True if the password is validated.    if st.session_state.get("password_correct", False):        if st.session_state["available"]:            return True        # show input for user name    st.session_state["user_name"] = st.text_input(        "Your name", type="default"    )    # Show input for password.    st.text_input(        "Password", type="password", on_change=password_entered, key="password"    )    if "password_correct" in st.session_state:        st.error("Password incorrect")    return Falseif not check_password():    st.stop()  # Do not continue if check_password is not True.    # app setup# headerheader = st.container()header.title("UNCTAD LLM")header.write("""<div class='fixed-header'/>""", unsafe_allow_html=True)### Custom CSS for the sticky headerst.markdown(    """<style>    div[data-testid="stVerticalBlock"] div:has(div.fixed-header) {        position: sticky;        top: 2.875rem;        background-color: white;        z-index: 999;    }    .fixed-header {        border-bottom: 0px solid black;    }</style>    """,    unsafe_allow_html=True)# Do not continue if a new user has booted off this oneif st.session_state["user_name"] != st.session_state["last_user"] and "user_recorded" in st.session_state:    if "model" in st.session_state:        st.session_state["model"].close_connection()        del st.session_state["model"].llm        del st.session_state["model"]        gc.collect()    st.error("A new user has logged on. Refresh in 3 minutes, if they have stopped using it you will be able to log in.")    st.stop()    # record the userif "user_recorded" not in st.session_state:    f = open("metadata/user.txt", "w")    f.write(st.session_state["user_name"])    f.close()    st.session_state["user_recorded"] = True    server_state["user_name"] = st.session_state["user_name"]print(f'New user: {server_state["user_name"]}')    # record last interactionf = open("metadata/last_used.txt", "w")f.write(str(datetime.now()))f.close()# Styles sheetswith open( "styles/style.css" ) as css:    st.markdown( f'<style>{css.read()}</style>' , unsafe_allow_html= True)    user_avatar = "https://www.svgrepo.com/show/524211/user.svg"#"\N{grinning face}"assistant_avatar = "https://www.svgrepo.com/show/375527/ai-platform.svg"#"\N{Robot Face}"# LLM set up# parameters/authenticationllm_dict = pd.read_csv("metadata/llm_list.csv")corpora_dict = pd.read_csv("metadata/corpora_list.csv")db_info = pd.read_csv("metadata/db_creds.csv")# model paramssimilarity_top_k = 4n_gpu_layers = 100temperature = 0.0max_new_tokens = 512context_window = 3900chunk_overlap = 200chunk_size = 512memory_limit = 1500system_prompt = ""paragraph_separator = "\n\n\n"separator = " "use_chat_engine = Truereset_chat_engine = Falsedb_name = "vector_db"rerun_populate_db = Falseclear_database = Falseif "model" not in st.session_state:    with st.spinner('Initializing...'):        st.session_state["model"], st.session_state["which_llm"], st.session_state["which_corpus"] = initialize(            which_llm_local="mistral-docsgpt",            which_corpus_local='imf',            n_gpu_layers=n_gpu_layers,            temperature=temperature,            max_new_tokens=max_new_tokens,            context_window=context_window,            chunk_overlap=chunk_overlap,            chunk_size=chunk_size,            paragraph_separator=paragraph_separator,            separator=separator,            system_prompt=system_prompt,            rerun_populate_db=rerun_populate_db,            clear_database_local=clear_database,            corpora_dict=corpora_dict,            llm_dict=llm_dict,            db_name=db_name,            db_info=db_info,        )# Initialize chat historyif "messages" not in st.session_state:    st.session_state.messages = []# Display chat messages from history on app rerunfor message in st.session_state.messages:    avatar = user_avatar if message["role"] == "user" else assistant_avatar    with st.chat_message(message["role"], avatar=avatar):        if "source_string" not in message["content"]:            st.markdown(message["content"])        else:            st.markdown("Sources: ", unsafe_allow_html=True, help=message["content"].split("string:")[1])# Accept user inputif prompt := st.chat_input(f'Query the \'{st.session_state["which_llm"]}\' LLM contextualized on the \'{st.session_state["which_corpus"]}\' corpus'):    # Display user message in chat message container    with st.chat_message("user", avatar=user_avatar):        st.markdown(prompt)    # Add user message to chat history    st.session_state.messages.append({"role": "user", "content": prompt})        # record last interaction    f = open("metadata/last_used.txt", "w")    f.write(str(datetime.now()))    f.close()        if prompt.lower() == "reset":        if st.session_state["model"].chat_engine is not None:            st.session_state["model"].chat_engine.reset()        with st.chat_message("assistant", avatar=assistant_avatar):            st.markdown("Model context reset!")                elif prompt.lower() == "clear":        if "model" in st.session_state:            if st.session_state["which_corpus"] is not None:                st.session_state["model"].close_connection()            del st.session_state["model"].llm            del st.session_state["model"]            gc.collect()        with st.chat_message("assistant", avatar=assistant_avatar):            st.markdown("Model cleared from memory!")        else:        response = st.session_state["model"].gen_response(            st.session_state.messages[-1]["content"].replace("cite your sources", "").replace("Cite your sources", ""),            similarity_top_k=similarity_top_k,            use_chat_engine=use_chat_engine,            reset_chat_engine=reset_chat_engine,            streaming=True,        )        def streamed_response(streamer):            with st.spinner('Thinking...'):                for token in streamer.response_gen:                    yield token        # Display assistant response in chat message container        with st.chat_message("assistant", avatar=assistant_avatar):            st.write_stream(streamed_response(response["response"]))        # adding sources        with st.chat_message("assistant", avatar=assistant_avatar):            if len(response.keys()) > 1: # only do if RAG                # markdown help way                source_string = ""                counter = 1                for j in list(pd.Series(list(response.keys()))[pd.Series(list(response.keys())) != "response"]):                    #source_string += f"**Source {counter}**:\n\n \t\t{response[j]}\n\n\n\n"                    metadata_dict = eval(response[j].split("| source text:")[0].replace("metadata: ", ""))                    metadata_string = ""                    for key, value in metadata_dict.items():                        metadata_string += f"'{key}': '{value}'\n"                                        source_string += f"""# Source {counter}\n ### Metadata:\n ```{metadata_string}```\n ### Text:\n{response[j].split("| source text:")[1]}\n\n"""                    counter += 1            else:                source_string = "NA"            st.markdown("Sources: ", unsafe_allow_html=True, help = f"{source_string}")        # Add assistant response to chat history        st.session_state.messages.append({"role": "assistant", "content": response["response"].response})        st.session_state.messages.append({"role": "assistant", "content": f"source_string:{source_string}"})